# -*- coding: utf-8 -*-
"""FINAL_PHYTOLENS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vGykA6m_yEqm00qGM6mlxHDOXl38Mn-P

# **PHYTOLENS : A PLANT DISEASE DETECTION MACHINE LEARNING PROJECT**

IMPORTING NECCESSARY LIBRARIES
"""

import tensorflow as tf
import matplotlib.pyplot as plt
import pandas as pd
import seaborn as sns

"""I HAVE UPLOADED THE DATASET IN DRIVE SO NOW FETCHING FROM THERE"""

from google.colab import drive
drive.mount('/content/drive')

"""EXTENSION OF THE DATASET WAS .rar"""

!sudo apt-get install unrar

# Path to the .rar file
rar_path = '/content/drive/MyDrive/Dataset.rar'

# Destination directory for extraction
extract_path = '/content/Dataset1'

# Extract using unrar
!unrar x "{rar_path}" "{extract_path}/"
print("Dataset extracted successfully!")

"""LISTING ALL THE DIFFERENT FOLDERS UNDER DATASET"""

!ls /content/Dataset1

!ls /content/Dataset1  # Check the contents of the main directory
!ls /content/Dataset1/Dataset  # Check if there is an extra subdirectory
!ls /content/Dataset1/Dataset/train  # Verify the train directory

"""# MODEL MAKING STARTS FROM HERE"""

training_set = tf.keras.utils.image_dataset_from_directory(
    '/content/Dataset1/Dataset/train',
    labels="inferred",
    label_mode="categorical",
    class_names=None,
    color_mode="rgb",
    batch_size=32,
    image_size=(128, 128),
    shuffle=True,
    seed=None,
    validation_split=None,
    subset=None,
    interpolation="bilinear",
    follow_links=False,
    crop_to_aspect_ratio=False
)

validation_set = tf.keras.utils.image_dataset_from_directory(
    '/content/Dataset1/Dataset/valid',
    labels="inferred",
    label_mode="categorical",
    class_names=None,
    color_mode="rgb",
    batch_size=32,
    image_size=(128, 128),
    shuffle=True,
    seed=None,
    validation_split=None,
    subset=None,
    interpolation="bilinear",
    follow_links=False,
    crop_to_aspect_ratio=False
)

"""The tf.keras.models.Sequential is a class in TensorFlow's Keras API used to create a linear stack of layers for building neural networks. When using Sequential, each layer is added one after another, forming a straightforward flow from input to output."""

cnn = tf.keras.models.Sequential()#Layers are added to the model one at a time using the .add() method or directly during initialization of sequential model

#First Convolutional Layer
cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,padding='same',activation='relu',input_shape=[128,128,3]))
#Second Convolutional Layer
cnn.add(tf.keras.layers.Conv2D(filters=32,kernel_size=3,activation='relu'))
#Third Convolutional Layer
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))

"""Purpose of Each Layer

  1. First Conv Layer: Extracts basic features like edges, corners, and textures from the input image.
  2. Second Conv Layer: Builds upon the initial features, capturing more complex patterns and structures.
  3. Max Pooling Layer: Reduces the spatial dimensions, retaining only the most prominent features while lowering computation requirements.
"""

cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,padding='same',activation='relu'))
cnn.add(tf.keras.layers.Conv2D(filters=64,kernel_size=3,activation='relu'))
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))

"""After these layers, the feature maps will have increased depth (64 filters), but their spatial dimensions (height and width) will have reduced due to pooling."""

cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3,padding='same',activation='relu',input_shape=[128,128,3]))
cnn.add(tf.keras.layers.Conv2D(filters=128,kernel_size=3,activation='relu'))
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))

"""Increasing filters enhances the modelâ€™s ability to learn more intricate details at deeper levels in the network, making it better at understanding more complex aspects of the input data."""

cnn.add(tf.keras.layers.Conv2D(filters=256,kernel_size=3,padding='same',activation='relu'))
cnn.add(tf.keras.layers.Conv2D(filters=256,kernel_size=3,activation='relu'))
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))

"""Increasing Filters to 256:

  * These layers will capture even more complex, abstract features from the data. The larger number of filters allows the network to learn a greater variety of patterns.
  * The depth of the feature map will increase significantly, allowing the network to represent more high-level information.
"""

cnn.add(tf.keras.layers.Conv2D(filters=512,kernel_size=3,padding='same',activation='relu'))
cnn.add(tf.keras.layers.Conv2D(filters=512,kernel_size=3,activation='relu'))
cnn.add(tf.keras.layers.MaxPool2D(pool_size=2,strides=2))

"""The network becomes more powerful at capturing very high-level features and abstract patterns. It learns to recognize even more complex structures, making it suitable for tasks where fine-grained distinctions between features are crucial"""

cnn.add(tf.keras.layers.Dropout(0.25))#0.25: This parameter specifies the dropout rate, meaning 25% of the neurons in this layer will be randomly "dropped out".

"""Flatten Layer is used to convert the output of convolutional and pooling layers into a 1D array (vector) so that it can be passed to fully connected (dense) layers.
It is a necessary step to transition from feature extraction (via convolution) to prediction (via dense layers).
"""

cnn.add(tf.keras.layers.Flatten())

cnn.add(tf.keras.layers.Dense(units=1500,activation='relu'))#In this case, the dense layer has 1500 neurons.Each neuron receives input from every unit in the previous layer

cnn.add(tf.keras.layers.Dropout(0.4)) #To avoid overfitting

"""model will have 38 output neurons.

  Each neuron in this layer corresponds to one class, and the network will output a prediction for each class.
"""

cnn.add(tf.keras.layers.Dense(units=38,activation='softmax'))#Softmax converts the raw output of the network (called logits) into probabilities by applying the exponential function to each output value and normalizing them.

cnn.compile(optimizer=tf.keras.optimizers.Adam(
    learning_rate=0.0001),loss='categorical_crossentropy',metrics=['accuracy'])

cnn.summary()

training_history = cnn.fit(x=training_set,validation_data=validation_set,epochs=10)

#Training set Accuracy
train_loss, train_acc = cnn.evaluate(training_set)
print('Training accuracy:', train_acc)

#Validation set Accuracy
val_loss, val_acc = cnn.evaluate(validation_set)
print('Validation accuracy:', val_acc)

cnn.save('trained_plant_disease_model.keras')

training_history.history #Return Dictionary of history

#Recording History in json
import json
with open('training_hist.json','w') as f:
  json.dump(training_history.history,f)

print(training_history.history.keys())

epochs = [i for i in range(1,11)]
plt.plot(epochs,training_history.history['accuracy'],color='brown',label='Training Accuracy')
plt.plot(epochs,training_history.history['val_accuracy'],color='green',label='Validation Accuracy')
plt.xlabel('No. of Epochs')
plt.title('Visualization of Accuracy Result')
plt.legend()
plt.show()

class_name = validation_set.class_names

test_set = tf.keras.utils.image_dataset_from_directory(
    '/content/Dataset1/Dataset/valid',
    labels="inferred",
    label_mode="categorical",
    class_names=None,
    color_mode="rgb",
    batch_size=1,
    image_size=(128, 128),
    shuffle=False,
    seed=None,
    validation_split=None,
    subset=None,
    interpolation="bilinear",
    follow_links=False,
    crop_to_aspect_ratio=False
)

y_pred = cnn.predict(test_set)
predicted_categories = tf.argmax(y_pred, axis=1)

true_categories = tf.concat([y for x, y in test_set], axis=0)
Y_true = tf.argmax(true_categories, axis=1)

Y_true

predicted_categories

from sklearn.metrics import confusion_matrix,classification_report
cm = confusion_matrix(Y_true,predicted_categories)

print(classification_report(Y_true,predicted_categories,target_names=class_name))

plt.figure(figsize=(40, 40))
sns.heatmap(cm,annot=True,annot_kws={"size": 10}, cmap='tab10')

plt.xlabel('Predicted Class',fontsize = 30)
plt.ylabel('Actual Class',fontsize = 40)
plt.title('Plant Disease Prediction Confusion Matrix',fontsize = 25)
plt.show()

validation_set = tf.keras.utils.image_dataset_from_directory(
    '/content/Dataset1/Dataset/valid' ,
    labels="inferred",
    label_mode="categorical",
    class_names=None,
    color_mode="rgb",
    batch_size=32,
    image_size=(128, 128),
    shuffle=True,
    seed=None,
    validation_split=None,
    subset=None,
    interpolation="bilinear",
    follow_links=False,
    crop_to_aspect_ratio=False
)
class_name = validation_set.class_names
print(class_name)

cnn = tf.keras.models.load_model('trained_plant_disease_model.keras')

import cv2
import os

image_path = "/content/01647a51-6ee5-4686-8f60-26ebed68fe21___RS_L.Scorch 0130.JPG"
assert os.path.exists(image_path), f"File not found: {image_path}"

# Try loading the image
img = cv2.imread(image_path)
if img is None:
    raise ValueError(f"Failed to read image at {image_path}. Ensure the path and format are correct.")

# Convert and display
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
import matplotlib.pyplot as plt
plt.imshow(img)
plt.show()

import numpy as np

image = tf.keras.preprocessing.image.load_img(image_path,target_size=(128,128))
input_arr = tf.keras.preprocessing.image.img_to_array(image)
input_arr = np.array([input_arr])  # Convert single image to a batch.
predictions = cnn.predict(input_arr)

print(predictions)

result_index = np.argmax(predictions) #Return index of max element
print(result_index)

# Displaying the disease prediction
model_prediction = class_name[result_index]
plt.imshow(img)
plt.title(f"Disease Name: {model_prediction}")
plt.xticks([])
plt.yticks([])
plt.show()

image_path = "/content/Orange___Haunglongbing_(Citrus_greening).JPG"
assert os.path.exists(image_path), f"File not found: {image_path}"

# Try loading the image
img = cv2.imread(image_path)
if img is None:
    raise ValueError(f"Failed to read image at {image_path}. Ensure the path and format are correct.")

# Convert and display
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
import matplotlib.pyplot as plt
plt.imshow(img)
plt.show()

image = tf.keras.preprocessing.image.load_img(image_path,target_size=(128,128))
input_arr = tf.keras.preprocessing.image.img_to_array(image)
input_arr = np.array([input_arr])  # Convert single image to a batch.
predictions = cnn.predict(input_arr)

print(predictions)

result_index = np.argmax(predictions) #Return index of max element
print(result_index)

# Displaying the disease prediction
model_prediction = class_name[result_index]
plt.imshow(img)
plt.title(f"Disease Name: {model_prediction}")
plt.xticks([])
plt.yticks([])
plt.show()

"""# FINAL STEPS TO MAKE AN APP USING FLASK

## 1. TRAINING
"""

import tensorflow as tf
from tensorflow.keras.preprocessing import image_dataset_from_directory

# Load the datasets
training_set = image_dataset_from_directory(
    '/content/Dataset1/Dataset/train',
    labels="inferred",
    label_mode="categorical",
    image_size=(128, 128),
    batch_size=32,
    shuffle=True
)

validation_set = image_dataset_from_directory(
    '/content/Dataset1/Dataset/valid',
    labels="inferred",
    label_mode="categorical",
    image_size=(128, 128),
    batch_size=32,
    shuffle=True
)

# Define the CNN model
cnn = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=[128, 128, 3]),
    tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'),
    tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),
    tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu'),
    tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'),
    tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),
    tf.keras.layers.Conv2D(filters=128, kernel_size=3, padding='same', activation='relu'),
    tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu'),
    tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),
    tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same', activation='relu'),
    tf.keras.layers.Conv2D(filters=256, kernel_size=3, activation='relu'),
    tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),
    tf.keras.layers.Conv2D(filters=512, kernel_size=3, padding='same', activation='relu'),
    tf.keras.layers.Conv2D(filters=512, kernel_size=3, activation='relu'),
    tf.keras.layers.MaxPooling2D(pool_size=2, strides=2),
    tf.keras.layers.Dropout(0.25),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(units=1500, activation='relu'),
    tf.keras.layers.Dropout(0.4),
    tf.keras.layers.Dense(units=38, activation='softmax')
])

# Compile the model
cnn.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])

# Print the model summary
cnn.summary()

# Train the model
training_history = cnn.fit(x=training_set, validation_data=validation_set, epochs=10)

# Evaluate the model
train_loss, train_acc = cnn.evaluate(training_set)
print('Training accuracy:', train_acc)
val_loss, val_acc = cnn.evaluate(validation_set)
print('Validation accuracy:', val_acc)

# Save the model
cnn.save('trained_plant_disease_model.keras')

"""## 2. TESTING"""

image_path = "/content/apple.png"
assert os.path.exists(image_path), f"File not found: {image_path}"

# Try loading the image
img = cv2.imread(image_path)
if img is None:
    raise ValueError(f"Failed to read image at {image_path}. Ensure the path and format are correct.")

# Convert and display
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
image = tf.keras.preprocessing.image.load_img(image_path,target_size=(128,128))
input_arr = tf.keras.preprocessing.image.img_to_array(image)
input_arr = np.array([input_arr])  # Convert single image to a batch.

cnn = tf.keras.models.load_model('trained_plant_disease_model.keras')

# Define class names for the predictions (ensure these are in the correct order)
class_name = [
    'Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy',
    'Blueberry___healthy', 'Cherry_(including_sour)___healthy', 'Cherry_(including_sour)___Powdery_mildew',
    'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_',
    'Corn_(maize)___healthy', 'Corn_(maize)___Northern_Leaf_Blight', 'Grape___Black_rot',
    'Grape___Esca_(Black_Measles)', 'Grape___healthy', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',
    'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy',
    'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight',
    'Potato___healthy', 'Potato___Late_blight', 'Raspberry___healthy', 'Soybean___healthy',
    'Squash___Powdery_mildew', 'Strawberry___healthy', 'Strawberry___Leaf_scorch',
    'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___healthy', 'Tomato___Late_blight',
    'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite',
    'Tomato___Target_Spot', 'Tomato___Tomato_mosaic_virus', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus'
]

predictions = cnn.predict(input_arr)
print(predictions)
result_index = np.argmax(predictions) #Return index of max element
print(result_index)
# Displaying the disease prediction
model_prediction = class_name[result_index]
plt.imshow(img)
plt.title(f"Disease Name: {model_prediction}")
plt.xticks([])
plt.yticks([])
plt.show()

import tensorflow as tf
import numpy as np
import os
import cv2
import matplotlib.pyplot as plt
from PIL import Image

# Path to the image to be tested
image_path = "/content/Grape___Black_rot.JPG"
assert os.path.exists(image_path), f"File not found: {image_path}"

# Try loading the image using OpenCV
img = cv2.imread(image_path)
if img is None:
    raise ValueError(f"Failed to read image at {image_path}. Ensure the path and format are correct.")

# Convert the image to RGB
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# Preprocess the image for prediction
image = tf.keras.preprocessing.image.load_img(image_path, target_size=(128, 128))
input_arr = tf.keras.preprocessing.image.img_to_array(image)
input_arr = np.array([input_arr])  # Convert single image to a batch

# Load the trained model
model_path = 'trained_plant_disease_model.keras'
cnn = tf.keras.models.load_model(model_path)

# Define class names for the predictions (ensure these are in the correct order)
class_name = [
    'Apple___Apple_scab', 'Apple___Black_rot', 'Apple___Cedar_apple_rust', 'Apple___healthy',
    'Blueberry___healthy', 'Cherry_(including_sour)___healthy', 'Cherry_(including_sour)___Powdery_mildew',
    'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot', 'Corn_(maize)___Common_rust_',
    'Corn_(maize)___healthy', 'Corn_(maize)___Northern_Leaf_Blight', 'Grape___Black_rot',
    'Grape___Esca_(Black_Measles)', 'Grape___healthy', 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)',
    'Orange___Haunglongbing_(Citrus_greening)', 'Peach___Bacterial_spot', 'Peach___healthy',
    'Pepper,_bell___Bacterial_spot', 'Pepper,_bell___healthy', 'Potato___Early_blight',
    'Potato___healthy', 'Potato___Late_blight', 'Raspberry___healthy', 'Soybean___healthy',
    'Squash___Powdery_mildew', 'Strawberry___healthy', 'Strawberry___Leaf_scorch',
    'Tomato___Bacterial_spot', 'Tomato___Early_blight', 'Tomato___healthy', 'Tomato___Late_blight',
    'Tomato___Leaf_Mold', 'Tomato___Septoria_leaf_spot', 'Tomato___Spider_mites Two-spotted_spider_mite',
    'Tomato___Target_Spot', 'Tomato___Tomato_mosaic_virus', 'Tomato___Tomato_Yellow_Leaf_Curl_Virus'
]

# Make predictions
predictions = cnn.predict(input_arr)
print(predictions)

# Get the index of the highest prediction
result_index = np.argmax(predictions)
print(result_index)

# Get the disease name from the class names list
model_prediction = class_name[result_index]

# Display the image with the predicted disease name
plt.imshow(img)
plt.title(f"Disease Name: {model_prediction}")
plt.xticks([])
plt.yticks([])
plt.show()